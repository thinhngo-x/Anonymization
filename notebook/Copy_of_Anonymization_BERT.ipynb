{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (INF442)",
      "language": "python",
      "name": "inf442_pi9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Copy of Anonymization_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinhngo-x/Anonymization/blob/alwin/Copy_of_Anonymization_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11A6KPFoda4x",
        "colab_type": "code",
        "outputId": "f86008f3-cb64-498a-cbd8-8c3395278bb5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        }
      },
      "source": [
        "from urllib.request import urlopen\n",
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testa\"\n",
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.train\"\n",
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testb\"\n",
        "# html = urlopen(url)\n",
        "# with open('eng.testb', 'b') as the_file:\n",
        "#     for line in html:\n",
        "#         the_file.write(line.decode('UTF-8'))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File ‘eng.testa’ already there; not retrieving.\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-05249782a77a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0murllib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0murlopen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testa\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.train\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msystem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testb\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# html = urlopen(url)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_shell.py\u001b[0m in \u001b[0;36msystem\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    100\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'also_return_output'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_system_commands\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_system_compat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint:disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mpip_warn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_system_compat\u001b[0;34m(shell, cmd, also_return_output)\u001b[0m\n\u001b[1;32m    436\u001b[0m   \u001b[0;31m# stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m   result = _run_command(\n\u001b[0;32m--> 438\u001b[0;31m       shell.var_expand(cmd, depth=2), clear_streamed_output=False)\n\u001b[0m\u001b[1;32m    439\u001b[0m   \u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser_ns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'_exit_code'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreturncode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0m_INTERRUPTED_SIGNALS\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_run_command\u001b[0;34m(cmd, clear_streamed_output)\u001b[0m\n\u001b[1;32m    193\u001b[0m       \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_pty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    194\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 195\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0m_monitor_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparent_pty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcmd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mupdate_stdin_widget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    196\u001b[0m   \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    197\u001b[0m     \u001b[0mepoll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.6/contextlib.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, type, value, traceback)\u001b[0m\n\u001b[1;32m     86\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m                 \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_system_commands.py\u001b[0m in \u001b[0;36m_display_stdin_widget\u001b[0;34m(delay_millis)\u001b[0m\n\u001b[1;32m    353\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    354\u001b[0m   \u001b[0mhide_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'cell_remove_stdin'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m   \u001b[0m_message\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mblocking_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mhide_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_header\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    357\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    169\u001b[0m   \u001b[0;31m# unique.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m   \u001b[0mrequest_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msend_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m     99\u001b[0m     \u001b[0mreply\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_read_next_input_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreply\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_NOT_READY\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 101\u001b[0;31m       \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.025\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    102\u001b[0m       \u001b[0;32mcontinue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m     if (reply.get('type') == 'colab_reply' and\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnAXLtsz3pCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WNUT17 Dataset https://github.com/leondz/emerging_entities_17\n",
        "\n",
        "! wget -nc \"https://raw.githubusercontent.com/leondz/emerging_entities_17/master/wnut17train.conll\"\n",
        "! wget -nc \"https://raw.githubusercontent.com/leondz/emerging_entities_17/master/emerging.test.conll\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6JUOiuOda4n",
        "colab_type": "text"
      },
      "source": [
        "# Projet informatique 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldkYBl17da4p",
        "colab_type": "text"
      },
      "source": [
        "## GDPR in practice: data anonymization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QA4dlIlRda4r",
        "colab_type": "text"
      },
      "source": [
        "This quick notebook will show you how to anonymize text data automatically. You'll have to do the same, by testing other approaches and / or embeddings and / or classification algorithms."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33z36ycnda4s",
        "colab_type": "text"
      },
      "source": [
        "### Some dependencies and some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvAmCYtGoKk-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/Anonymization/CONLL2003_BERT/'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7DBPEgdcoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPayx1sda4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "import os\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWsk32s7da40",
        "colab_type": "text"
      },
      "source": [
        "### Some useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc1cSBdqda41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for token classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, words, labels):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            words: list. The words of the sequence.\n",
        "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.words = words\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids\n",
        "\n",
        "\n",
        "def read_examples_from_file(data_dir, mode=\"eng.testa\"):\n",
        "    file_path = os.path.join(data_dir, \"{}\".format(mode))\n",
        "    guid_index = 1\n",
        "    examples = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\" or line == \"\\t\\n\":\n",
        "                if words:\n",
        "                    examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "                    guid_index += 1\n",
        "                    words = []\n",
        "                    labels = []\n",
        "            else:\n",
        "                splits = line.split(\"\\t\")\n",
        "                print(splits)\n",
        "                words.append(splits[0])\n",
        "                if len(splits) > 1:\n",
        "                    # print(splits[-1])\n",
        "                    label = splits[-1].split(\",\")\n",
        "                    if \"B-person\" in label:\n",
        "                        labels.append(\"B-person\")\n",
        "                    elif \"I-person\" in label:\n",
        "                        labels.append(\"I-person\")\n",
        "                    else:\n",
        "                        labels.append(label[-1].replace(\"\\n\", \"\"))\n",
        "                else:\n",
        "                    # Examples could have no label for mode = \"test\"\n",
        "                    labels.append(\"O\")\n",
        "        if words:\n",
        "            examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "    return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    label_list,\n",
        "    max_seq_length,\n",
        "    tokenizer,\n",
        "    cls_token_at_end=False,\n",
        "    cls_token=\"[CLS]\",\n",
        "    cls_token_segment_id=1,\n",
        "    sep_token=\"[SEP]\",\n",
        "    sep_token_extra=False,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    pad_token_label_id=-100,\n",
        "    sequence_a_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
        "\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "        for word, label in zip(example.words, example.labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
        "            print(label, pad_token_label_id, word_tokens)\n",
        "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
        "        special_tokens_count = 3 if sep_token_extra else 2\n",
        "        if len(tokens) > max_seq_length - special_tokens_count:\n",
        "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens += [sep_token]\n",
        "        label_ids += [pad_token_label_id]\n",
        "        if sep_token_extra:\n",
        "            # roberta uses an extra separator b/w pairs of sentences\n",
        "            tokens += [sep_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if cls_token_at_end:\n",
        "            tokens += [cls_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "            segment_ids += [cls_token_segment_id]\n",
        "        else:\n",
        "            tokens = [cls_token] + tokens\n",
        "            label_ids = [pad_token_label_id] + label_ids\n",
        "            segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
        "        else:\n",
        "            input_ids += [pad_token] * padding_length\n",
        "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
        "            segment_ids += [pad_token_segment_id] * padding_length\n",
        "            label_ids += [pad_token_label_id] * padding_length\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        assert len(label_ids) == max_seq_length\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\", example.guid)\n",
        "            logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
        "        )\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bzviBducda44",
        "colab_type": "text"
      },
      "source": [
        "### A direct, pre-trained NER approach"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9QZGh1j6da44",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp = transformers.pipeline(\"ner\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Pbf3Msxda48",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nlp(\"Adrien Ehrhardt donne un projet d'informatique aux étudiants de INF442.\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfRrCqEda4_",
        "colab_type": "text"
      },
      "source": [
        "### Obtaining the representation of the dataset from Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwMVKuGda4_",
        "colab_type": "text"
      },
      "source": [
        "#### An example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3h3Obe4da5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FavsZF4yda5D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertModel.from_pretrained(\"bert-large-cased\").cuda()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-cased\")\n",
        "\n",
        "sequence = \"Adrien Ehrhardt donne un projet d'informatique aux étudiants de INF442.\"\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
        "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model(inputs.cuda())[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSKdTMeda5G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs.detach().cpu().numpy()[0].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ds8scvkda5J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhzG_pWda5L",
        "colab_type": "text"
      },
      "source": [
        "#### The real thing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od57D9FOda5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrG1tTdUda5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9xIXY5da5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuNLGm-Fda5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_token_label_id=CrossEntropyLoss().ignore_index\n",
        "labels = [\"O\", \"B-location\", \"I-location\", \"B-person\", \"I-person\", \"B-group\", \"I-group\",\n",
        "          \"B-corporation\", \"I-corporation\", \"B-product\", \"I-product\",\n",
        "          \"B-creative-work\", \"I-creative-work\"]\n",
        "model = BertModel.from_pretrained(\"bert-large-cased\").cuda()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-cased\")\n",
        "examples = read_examples_from_file(\".\", mode=\"emerging.test.conll\")\n",
        "print(examples[2].labels)\n",
        "features = convert_examples_to_features(\n",
        "            examples,\n",
        "            label_list = labels,\n",
        "            max_seq_length = 128,\n",
        "            tokenizer = tokenizer,\n",
        "            cls_token_at_end=False,\n",
        "            cls_token=tokenizer.cls_token,\n",
        "            cls_token_segment_id=0,\n",
        "            sep_token=tokenizer.sep_token,\n",
        "            sep_token_extra=False,\n",
        "            pad_on_left=False,\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=0,\n",
        "            pad_token_label_id=pad_token_label_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPz0UJrida5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnCUlAfNda5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_sampler = SequentialSampler(dataset)\n",
        "eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=32)\n",
        "preds = None\n",
        "out_label_ids = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAoyAuOTda5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "out_label_ids = []\n",
        "for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "    batch = tuple(t.to(\"cuda\") for t in batch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n",
        "        inputs[\"token_type_ids\"] = (\n",
        "            batch[2]\n",
        "        )\n",
        "        outputs = model(**inputs)\n",
        "        last_hidden_layer = outputs[0]\n",
        "        # if preds is None:\n",
        "        #     preds = last_hidden_layer.detach().cpu().numpy()\n",
        "        #     out_label_ids = batch[3].detach().cpu().numpy()\n",
        "        # else:\n",
        "        #     preds = np.append(preds, last_hidden_layer.detach().cpu().numpy(), axis=0)\n",
        "        #     out_label_ids = np.append(out_label_ids, batch[3].detach().cpu().numpy(), axis=0)\n",
        "        #     print(last_hidden_layer.shape)\n",
        "        #     print(batch[3].shape)\n",
        "        preds.append(last_hidden_layer.detach().cpu().numpy())\n",
        "        out_label_ids.append(batch[3].detach().cpu().numpy())\n",
        "        # preds[ite*32:(ite+1)*32,:,:] = last_hidden_layer.detach().cpu().numpy()\n",
        "        # out_label_ids[ite*32:(ite+1)*32,:,:] = out_label_ids.detach().cpu().numpy()\n",
        "        # ite += 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tDUOhY7yy0bd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_label_ids[-1].shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRNbBdKrda5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_label_list = [[] for _ in range(len(out_label_ids) * 32)]\n",
        "preds_list = [[] for _ in range(len(out_label_ids) * 32)]\n",
        "\n",
        "label_map = {i: label for i, label in enumerate(labels)}\n",
        "        \n",
        "for i in range(len(out_label_ids)):\n",
        "    for b in range(out_label_ids[i].shape[0]):\n",
        "        for j in range(out_label_ids[0].shape[1]):\n",
        "            if out_label_ids[i][b,j] != pad_token_label_id:\n",
        "                out_label_list[i*32+b].append(out_label_ids[i][b,j])\n",
        "                preds_list[i*32+b].append(preds[i][b,j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vkg_s1G6-d53",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_label_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQxpSYsda5f",
        "colab_type": "text"
      },
      "source": [
        "`out_label_list` is of shape (#number of sentences, #tokens in this sentence, 1)\n",
        "\n",
        "`preds_list` is of shape (#number of sentences, #tokens in this sentence, 1024 hidden representations)\n",
        "\n",
        "For the sake of simplicity, we'll consider that an observation / a sample is a token, not a sentence (the contextual meaning of each token is already taken into account in its representation), so we need to \"flatten\" both lists so that they're of shape (#tokens, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXeyeFmda5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wke-7lB0da5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = np.array(list(itertools.chain.from_iterable(out_label_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKEZxESda5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = []\n",
        "for sentence in preds_list:\n",
        "    for token in sentence:\n",
        "        flat_list.append(token)\n",
        "        \n",
        "representation = np.array(flat_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_PwQvVda5m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBdJ7I-Bda5o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWuf_bAda5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(root+\"true_labels.test.npy\", true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jl3k2zqHYzzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2wylJH9da5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(root+\"representation.test.npy\", representation)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XcLU7vDnda55",
        "colab_type": "text"
      },
      "source": [
        "### Loading for example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vwGCih7qda55",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = np.load(root+\"true_labels.train.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EskjYY8Xda57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4g-1Gj26da59",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation = np.load(root+\"representation.train.npy\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDYrQiMIda5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFVfVjYjO9RW",
        "colab_type": "text"
      },
      "source": [
        "### Example of classifier on top"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JVIEakgdO9RX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn as sk\n",
        "import sklearn.linear_model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkPLxweQO9RZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_top = sk.linear_model.LogisticRegressionCV()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "smLKe0oQO9Rb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_top.fit(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EK9vzrdHO9Rd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_top.score(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UfTgJNbVmwVA",
        "colab_type": "text"
      },
      "source": [
        "### Other Classifiers that we can use"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51WVab4In1Xm",
        "colab_type": "text"
      },
      "source": [
        "#### Naive-Bayes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKz0ePNBjIky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.naive_bayes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-mhiGs13nHjf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_NB = sk.naive_bayes.GaussianNB()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HuNwzurunMSE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_NB.fit(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugS1-BmcsK3Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feed in representation_test as 2D array and predict it\n",
        "#prediction_NB = model_NB.predict(representation)\n",
        "#print(\"Accuracy of Naive-Bayes : \",sk.metrics.accuracy_score(representation, prediction_NB, normalize = True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w7QcCtuunnNC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_NB.score(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v6OWzGmSn6eF",
        "colab_type": "text"
      },
      "source": [
        "#### Linear SVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mgMaJUzRmCPG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n4JOS_gxoAD1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_SVC = sk.svm.LinearSVC(random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PYbmNLNbodxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_SVC.fit(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iIwTJiBsM6U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feed in representation_test as 2D array and predict it\n",
        "#prediction_SVC = model_SVC.predict(representation_test)\n",
        "#print(\"Accuracy of Linear SVC : \",sk.metrics.accuracy_score(representation_test, prediction_SVC, normalize = True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JXMlFGpWo9hp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_SVC.score(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ID1yJfjpDyl",
        "colab_type": "text"
      },
      "source": [
        "#### K-Neighbors Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOODQTdzpdSg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k = 3 #number of neighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eftk3jtImU0k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn.neighbors"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E85uyEWOpQNl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_KNN = sk.neighbors.KNeighborsClassifier(n_neighbors = k)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQFfWdkLpQwI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_KNN.fit(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xaG9lyX8slJs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#feed in representation_test as 2D array and predict it\n",
        "#prediction_KNN = model_KNN.predict(representation_test)\n",
        "#print(\"Accuracy of K-Neighbors Classifier : \",sk.metrics.accuracy_score(representation_test, prediction_KNN, normalize = True))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GInXeqC0pRSk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_KNN.score(X=representation, y=true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qSTVXZNqda6H",
        "colab_type": "text"
      },
      "source": [
        "### Loading and converting to CSV: files get too big, you'll have to do this yourself and sample!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SvplsuwMda6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from random import sample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2WC1r6Xhda6K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation = np.load(\"representation.train.npy\")\n",
        "# SAMPLE\n",
        "int_train = sample(range(representation.shape[0]), 10000)\n",
        "np.savetxt(\"representation.train.csv\", representation[int_train,:], delimiter=\",\")\n",
        "true_labels = np.load(\"true_labels.train.npy\")\n",
        "np.savetxt(\"true_labels.train.csv\", true_labels[int_train], delimiter=\",\", fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "znkIod_4da6N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation = np.load(\"representation.testa.npy\")\n",
        "# SAMPLE\n",
        "int_train = sample(range(representation.shape[0]), 2000)\n",
        "np.savetxt(\"representation.testa.csv\", representation[int_train,:], delimiter=\",\")\n",
        "true_labels = np.load(\"true_labels.testa.npy\")\n",
        "np.savetxt(\"true_labels.testa.csv\", true_labels[int_train], delimiter=\",\", fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tAWksGX4da6P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "representation = np.load(\"representation.testb.npy\")\n",
        "# SAMPLE\n",
        "int_train = sample(range(representation.shape[0]), 2000)\n",
        "np.savetxt(\"representation.testb.csv\", representation[int_train,:], delimiter=\",\")\n",
        "true_labels = np.load(\"true_labels.testb.npy\")\n",
        "np.savetxt(\"true_labels.testb.csv\", true_labels[int_train], delimiter=\",\", fmt='%s')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "41630GtFda6T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
