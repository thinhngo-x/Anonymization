{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python (INF442)",
      "language": "python",
      "name": "inf442_pi9"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "Anonymization_BERT.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "bzviBducda44"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e8e5153087c1482f8b63e8c5bf4ce656": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7dccd87b9f0141bb9c79c21a700cc311",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_cdbc98579f794b9e8731f3215137ebed",
              "IPY_MODEL_059f00e57d984d4eb947479de38b66b3"
            ]
          }
        },
        "7dccd87b9f0141bb9c79c21a700cc311": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cdbc98579f794b9e8731f3215137ebed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_86be3cc87f314980939560837dc8a698",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1338740706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1338740706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a5a5f927b1894f13860e8e5b06c283a0"
          }
        },
        "059f00e57d984d4eb947479de38b66b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5d6d6eeee2c47d0aba1345cb53f5249",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:38&lt;00:00, 34.8MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3036e95849764028bb121b9289530771"
          }
        },
        "86be3cc87f314980939560837dc8a698": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a5a5f927b1894f13860e8e5b06c283a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5d6d6eeee2c47d0aba1345cb53f5249": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3036e95849764028bb121b9289530771": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c3e3a8f659f94dfaa185b3cb77c75369": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7900fa43150241cf892588f21a4fb4eb",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_eeeeb052222940d59422cb3abdebf6ca",
              "IPY_MODEL_d1e06ccf153e44f9970dc2d573fbed3e"
            ]
          }
        },
        "7900fa43150241cf892588f21a4fb4eb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eeeeb052222940d59422cb3abdebf6ca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5fec151d3f24ec99add27673964faf7",
            "_dom_classes": [],
            "description": "Evaluating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 41,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 41,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85d09e402ed9487c8985cf7bdb72b802"
          }
        },
        "d1e06ccf153e44f9970dc2d573fbed3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c4dd6cb158cc41dc9ef218d5cbbfe77a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 41/41 [00:28&lt;00:00,  1.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c074384cac2c4c039804b13a17c14dcd"
          }
        },
        "b5fec151d3f24ec99add27673964faf7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85d09e402ed9487c8985cf7bdb72b802": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c4dd6cb158cc41dc9ef218d5cbbfe77a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c074384cac2c4c039804b13a17c14dcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thinhngo-x/Anonymization/blob/alwin/notebook/Anonymization_BERT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11A6KPFoda4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testa\" --quiet\n",
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.train\" --quiet\n",
        "! wget -nc \"https://raw.githubusercontent.com/glample/tagger/master/dataset/eng.testb\" --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnAXLtsz3pCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# WNUT17 Dataset https://github.com/leondz/emerging_entities_17\n",
        "\n",
        "! wget -nc \"https://raw.githubusercontent.com/leondz/emerging_entities_17/master/wnut17train.conll\" --quiet\n",
        "! wget -nc \"https://raw.githubusercontent.com/leondz/emerging_entities_17/master/emerging.test.conll\" --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "33z36ycnda4s",
        "colab_type": "text"
      },
      "source": [
        "### Some dependencies and some data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VvAmCYtGoKk-",
        "colab_type": "code",
        "outputId": "4b45e5fd-46df-471f-f946-577697b0d8e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "root = '/content/drive/My Drive/Anonymization/WNUT17_BERT/'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nw7DBPEgdcoh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! pip install transformers --quiet"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vPayx1sda4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import transformers\n",
        "import os\n",
        "from torch.nn import CrossEntropyLoss\n",
        "import logging\n",
        "logger = logging.getLogger(__name__)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWsk32s7da40",
        "colab_type": "text"
      },
      "source": [
        "### Some useful functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Oc1cSBdqda41",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for token classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, words, labels):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            words: list. The words of the sequence.\n",
        "            labels: (Optional) list. The labels for each word of the sequence. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.words = words\n",
        "        self.labels = labels\n",
        "\n",
        "\n",
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_ids):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_ids = label_ids\n",
        "\n",
        "\n",
        "def read_examples_from_file(data_dir, mode=\"eng.testa\"):\n",
        "    file_path = os.path.join(data_dir, \"{}\".format(mode))\n",
        "    guid_index = 1\n",
        "    examples = []\n",
        "    with open(file_path, encoding=\"utf-8\") as f:\n",
        "        words = []\n",
        "        labels = []\n",
        "        for line in f:\n",
        "            if line.startswith(\"-DOCSTART-\") or line == \"\" or line == \"\\n\" or line == \"\\t\\n\":\n",
        "                if words:\n",
        "                    examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "                    guid_index += 1\n",
        "                    words = []\n",
        "                    labels = []\n",
        "            else:\n",
        "                splits = line.split(\"\\t\")\n",
        "                # print(splits)\n",
        "                words.append(splits[0])\n",
        "                if len(splits) > 1:\n",
        "                    # print(splits[-1])\n",
        "                    label = splits[-1].split(\",\")\n",
        "                    if \"B-person\" in label:\n",
        "                        labels.append(\"B-person\")\n",
        "                    elif \"I-person\" in label:\n",
        "                        labels.append(\"I-person\")\n",
        "                    else:\n",
        "                        labels.append(label[-1].replace(\"\\n\", \"\"))\n",
        "                else:\n",
        "                    # Examples could have no label for mode = \"test\"\n",
        "                    labels.append(\"O\")\n",
        "        if words:\n",
        "            examples.append(InputExample(guid=\"{}-{}\".format(mode, guid_index), words=words, labels=labels))\n",
        "    return examples\n",
        "\n",
        "\n",
        "def convert_examples_to_features(\n",
        "    examples,\n",
        "    label_list,\n",
        "    max_seq_length,\n",
        "    tokenizer,\n",
        "    cls_token_at_end=False,\n",
        "    cls_token=\"[CLS]\",\n",
        "    cls_token_segment_id=1,\n",
        "    sep_token=\"[SEP]\",\n",
        "    sep_token_extra=False,\n",
        "    pad_on_left=False,\n",
        "    pad_token=0,\n",
        "    pad_token_segment_id=0,\n",
        "    pad_token_label_id=-100,\n",
        "    sequence_a_segment_id=0,\n",
        "    mask_padding_with_zero=True,\n",
        "):\n",
        "    \"\"\" Loads a data file into a list of `InputBatch`s\n",
        "        `cls_token_at_end` define the location of the CLS token:\n",
        "            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n",
        "            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n",
        "        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n",
        "    \"\"\"\n",
        "\n",
        "    label_map = {label: i for i, label in enumerate(label_list)}\n",
        "\n",
        "    features = []\n",
        "    for (ex_index, example) in enumerate(examples):\n",
        "        if ex_index % 10000 == 0:\n",
        "            logger.info(\"Writing example %d of %d\", ex_index, len(examples))\n",
        "\n",
        "        tokens = []\n",
        "        label_ids = []\n",
        "        for word, label in zip(example.words, example.labels):\n",
        "            word_tokens = tokenizer.tokenize(word)\n",
        "            tokens.extend(word_tokens)\n",
        "            # Use the real label id for the first token of the word, and padding ids for the remaining tokens\n",
        "            # print(label, pad_token_label_id, word_tokens)\n",
        "            label_ids.extend([label_map[label]] + [pad_token_label_id] * (len(word_tokens) - 1))\n",
        "\n",
        "        # Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.\n",
        "        special_tokens_count = 3 if sep_token_extra else 2\n",
        "        if len(tokens) > max_seq_length - special_tokens_count:\n",
        "            tokens = tokens[: (max_seq_length - special_tokens_count)]\n",
        "            label_ids = label_ids[: (max_seq_length - special_tokens_count)]\n",
        "\n",
        "        # The convention in BERT is:\n",
        "        # (a) For sequence pairs:\n",
        "        #  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]\n",
        "        #  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1\n",
        "        # (b) For single sequences:\n",
        "        #  tokens:   [CLS] the dog is hairy . [SEP]\n",
        "        #  type_ids:   0   0   0   0  0     0   0\n",
        "        #\n",
        "        # Where \"type_ids\" are used to indicate whether this is the first\n",
        "        # sequence or the second sequence. The embedding vectors for `type=0` and\n",
        "        # `type=1` were learned during pre-training and are added to the wordpiece\n",
        "        # embedding vector (and position vector). This is not *strictly* necessary\n",
        "        # since the [SEP] token unambiguously separates the sequences, but it makes\n",
        "        # it easier for the model to learn the concept of sequences.\n",
        "        #\n",
        "        # For classification tasks, the first vector (corresponding to [CLS]) is\n",
        "        # used as as the \"sentence vector\". Note that this only makes sense because\n",
        "        # the entire model is fine-tuned.\n",
        "        tokens += [sep_token]\n",
        "        label_ids += [pad_token_label_id]\n",
        "        if sep_token_extra:\n",
        "            # roberta uses an extra separator b/w pairs of sentences\n",
        "            tokens += [sep_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "        segment_ids = [sequence_a_segment_id] * len(tokens)\n",
        "\n",
        "        if cls_token_at_end:\n",
        "            tokens += [cls_token]\n",
        "            label_ids += [pad_token_label_id]\n",
        "            segment_ids += [cls_token_segment_id]\n",
        "        else:\n",
        "            tokens = [cls_token] + tokens\n",
        "            label_ids = [pad_token_label_id] + label_ids\n",
        "            segment_ids = [cls_token_segment_id] + segment_ids\n",
        "\n",
        "        input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "        # tokens are attended to.\n",
        "        input_mask = [1 if mask_padding_with_zero else 0] * len(input_ids)\n",
        "\n",
        "        # Zero-pad up to the sequence length.\n",
        "        padding_length = max_seq_length - len(input_ids)\n",
        "        if pad_on_left:\n",
        "            input_ids = ([pad_token] * padding_length) + input_ids\n",
        "            input_mask = ([0 if mask_padding_with_zero else 1] * padding_length) + input_mask\n",
        "            segment_ids = ([pad_token_segment_id] * padding_length) + segment_ids\n",
        "            label_ids = ([pad_token_label_id] * padding_length) + label_ids\n",
        "        else:\n",
        "            input_ids += [pad_token] * padding_length\n",
        "            input_mask += [0 if mask_padding_with_zero else 1] * padding_length\n",
        "            segment_ids += [pad_token_segment_id] * padding_length\n",
        "            label_ids += [pad_token_label_id] * padding_length\n",
        "\n",
        "        assert len(input_ids) == max_seq_length\n",
        "        assert len(input_mask) == max_seq_length\n",
        "        assert len(segment_ids) == max_seq_length\n",
        "        assert len(label_ids) == max_seq_length\n",
        "\n",
        "        if ex_index < 5:\n",
        "            logger.info(\"*** Example ***\")\n",
        "            logger.info(\"guid: %s\", example.guid)\n",
        "            logger.info(\"tokens: %s\", \" \".join([str(x) for x in tokens]))\n",
        "            logger.info(\"input_ids: %s\", \" \".join([str(x) for x in input_ids]))\n",
        "            logger.info(\"input_mask: %s\", \" \".join([str(x) for x in input_mask]))\n",
        "            logger.info(\"segment_ids: %s\", \" \".join([str(x) for x in segment_ids]))\n",
        "            logger.info(\"label_ids: %s\", \" \".join([str(x) for x in label_ids]))\n",
        "\n",
        "        features.append(\n",
        "            InputFeatures(input_ids=input_ids, input_mask=input_mask, segment_ids=segment_ids, label_ids=label_ids)\n",
        "        )\n",
        "    return features"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QfRrCqEda4_",
        "colab_type": "text"
      },
      "source": [
        "### Obtaining the representation of the dataset from Bert"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6nwMVKuGda4_",
        "colab_type": "text"
      },
      "source": [
        "#### An example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3h3Obe4da5A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertTokenizer, BertModel\n",
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FavsZF4yda5D",
        "colab_type": "code",
        "outputId": "18811055-ad0e-4d63-d81e-7f0a6835cf48",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "e8e5153087c1482f8b63e8c5bf4ce656",
            "7dccd87b9f0141bb9c79c21a700cc311",
            "cdbc98579f794b9e8731f3215137ebed",
            "059f00e57d984d4eb947479de38b66b3",
            "86be3cc87f314980939560837dc8a698",
            "a5a5f927b1894f13860e8e5b06c283a0",
            "e5d6d6eeee2c47d0aba1345cb53f5249",
            "3036e95849764028bb121b9289530771"
          ]
        }
      },
      "source": [
        "model = BertModel.from_pretrained(\"bert-large-cased\").cuda()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-cased\")\n",
        "\n",
        "sequence = \"Adrien Ehrhardt donne un projet d'informatique aux Ã©tudiants de INF442.\"\n",
        "tokens = tokenizer.tokenize(tokenizer.decode(tokenizer.encode(sequence)))\n",
        "inputs = tokenizer.encode(sequence, return_tensors=\"pt\")\n",
        "\n",
        "outputs = model(inputs.cuda())[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e8e5153087c1482f8b63e8c5bf4ce656",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1338740706.0, style=ProgressStyle(descrâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtSKdTMeda5G",
        "colab_type": "code",
        "outputId": "d82b0adc-5fa9-4879-af92-32273cf0acad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "outputs.detach().cpu().numpy()[0].shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(28, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ds8scvkda5J",
        "colab_type": "code",
        "outputId": "8fb26f36-3649-4a14-d5ad-1914508e29de",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "outputs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-0.3408, -0.5467,  0.3817,  ..., -0.3688, -0.3334,  0.2856],\n",
              "         [-0.5390, -0.9849, -0.2608,  ..., -0.4244,  0.1998, -0.3972],\n",
              "         [-0.5249,  0.2965,  0.0322,  ...,  0.8137,  0.4162, -0.4437],\n",
              "         ...,\n",
              "         [-0.6153,  0.5873,  0.0034,  ...,  0.0931,  0.1486,  0.5473],\n",
              "         [-0.5728, -0.4093, -0.3757,  ...,  0.3390,  0.0722, -0.3506],\n",
              "         [-0.7437, -0.5303, -0.8375,  ..., -0.5345,  0.6854, -0.2059]]],\n",
              "       device='cuda:0', grad_fn=<NativeLayerNormBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHhzG_pWda5L",
        "colab_type": "text"
      },
      "source": [
        "#### The real thing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "od57D9FOda5M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jrG1tTdUda5P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tqdm.notebook import tqdm, trange"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jn9xIXY5da5S",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuNLGm-Fda5U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pad_token_label_id=CrossEntropyLoss().ignore_index\n",
        "labels = [\"O\", \"B-location\", \"I-location\", \"B-person\", \"I-person\", \"B-group\", \"I-group\",\n",
        "          \"B-corporation\", \"I-corporation\", \"B-product\", \"I-product\",\n",
        "          \"B-creative-work\", \"I-creative-work\"]\n",
        "model = BertModel.from_pretrained(\"bert-large-cased\").cuda()\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-large-cased\")\n",
        "examples = read_examples_from_file(\".\", mode=\"emerging.test.conll\")\n",
        "# print(examples[2].labels)\n",
        "features = convert_examples_to_features(\n",
        "            examples,\n",
        "            label_list = labels,\n",
        "            max_seq_length = 128,\n",
        "            tokenizer = tokenizer,\n",
        "            cls_token_at_end=False,\n",
        "            cls_token=tokenizer.cls_token,\n",
        "            cls_token_segment_id=0,\n",
        "            sep_token=tokenizer.sep_token,\n",
        "            sep_token_extra=False,\n",
        "            pad_on_left=False,\n",
        "            pad_token=tokenizer.convert_tokens_to_ids([tokenizer.pad_token])[0],\n",
        "            pad_token_segment_id=0,\n",
        "            pad_token_label_id=pad_token_label_id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPz0UJrida5W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Convert to Tensors and build dataset\n",
        "all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
        "all_label_ids = torch.tensor([f.label_ids for f in features], dtype=torch.long)\n",
        "\n",
        "dataset = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EnCUlAfNda5Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eval_sampler = SequentialSampler(dataset)\n",
        "eval_dataloader = DataLoader(dataset, sampler=eval_sampler, batch_size=32)\n",
        "preds = None\n",
        "out_label_ids = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gAoyAuOTda5a",
        "colab_type": "code",
        "outputId": "c75eecf8-c609-4211-b0e3-17e959e808c0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 66,
          "referenced_widgets": [
            "c3e3a8f659f94dfaa185b3cb77c75369",
            "7900fa43150241cf892588f21a4fb4eb",
            "eeeeb052222940d59422cb3abdebf6ca",
            "d1e06ccf153e44f9970dc2d573fbed3e",
            "b5fec151d3f24ec99add27673964faf7",
            "85d09e402ed9487c8985cf7bdb72b802",
            "c4dd6cb158cc41dc9ef218d5cbbfe77a",
            "c074384cac2c4c039804b13a17c14dcd"
          ]
        }
      },
      "source": [
        "model.eval()\n",
        "preds = []\n",
        "out_label_ids = []\n",
        "for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
        "    batch = tuple(t.to(\"cuda\") for t in batch)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        inputs = {\"input_ids\": batch[0], \"attention_mask\": batch[1]}\n",
        "        inputs[\"token_type_ids\"] = (\n",
        "            batch[2]\n",
        "        )\n",
        "        outputs = model(**inputs)\n",
        "        last_hidden_layer = outputs[0]\n",
        "        preds.append(last_hidden_layer.detach().cpu().numpy())\n",
        "        out_label_ids.append(batch[3].detach().cpu().numpy())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c3e3a8f659f94dfaa185b3cb77c75369",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=41.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FRNbBdKrda5d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "out_label_list = [[] for _ in range(len(out_label_ids) * 32)]\n",
        "preds_list = [[] for _ in range(len(out_label_ids) * 32)]\n",
        "\n",
        "label_map = {i: label for i, label in enumerate(labels)}\n",
        "        \n",
        "for i in range(len(out_label_ids)):\n",
        "    for b in range(out_label_ids[i].shape[0]):\n",
        "        for j in range(out_label_ids[0].shape[1]):\n",
        "            if out_label_ids[i][b,j] != pad_token_label_id:\n",
        "                out_label_list[i*32+b].append(out_label_ids[i][b,j])\n",
        "                preds_list[i*32+b].append(preds[i][b,j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sQxpSYsda5f",
        "colab_type": "text"
      },
      "source": [
        "`out_label_list` is of shape (#number of sentences, #tokens in this sentence, 1)\n",
        "\n",
        "`preds_list` is of shape (#number of sentences, #tokens in this sentence, 1024 hidden representations)\n",
        "\n",
        "For the sake of simplicity, we'll consider that an observation / a sample is a token, not a sentence (the contextual meaning of each token is already taken into account in its representation), so we need to \"flatten\" both lists so that they're of shape (#tokens, 1)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mXeyeFmda5g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wke-7lB0da5i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "true_labels = np.array(list(itertools.chain.from_iterable(out_label_list)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJKEZxESda5k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "flat_list = []\n",
        "for sentence in preds_list:\n",
        "    for token in sentence:\n",
        "        flat_list.append(token)\n",
        "        \n",
        "representation = np.array(flat_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "te_PwQvVda5m",
        "colab_type": "code",
        "outputId": "95c41a5d-57d7-4c48-f39b-e519bb35aa15",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "true_labels.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23364,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GBdJ7I-Bda5o",
        "colab_type": "code",
        "outputId": "65d1c79e-7584-4882-c156-53ad10b1863f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "representation.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(23364, 1024)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rWuf_bAda5r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(root+\"true_labels.test.npy\", true_labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2wylJH9da5u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.save(root+\"representation.test.npy\", representation)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}